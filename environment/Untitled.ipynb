{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "# -*- coding: utf-8 -*-\n",
    "import random\n",
    "import math\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from keras.utils import plot_model\n",
    "import h5py\n",
    "from ann_visualizer.visualize import ann_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TeacherAgent:\n",
    "    def __init__(self, state_size=4, action_size=3):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "        self.moves_since_hint = 0\n",
    "        self.not_yet_rewarded = []\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if self.moves_since_hint == 2: #Meaning the teacher waits at most 3 moves for a reward, could be tweaked\n",
    "            self.moves_since_hint = 0\n",
    "            return 2 #This enforces that we don't go too long without giving hints (could change to full OR partial hint l8r)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            random_index = random.randrange(self.action_size)\n",
    "            if random_index == 0:\n",
    "                self.moves_since_hint += 1\n",
    "            else:\n",
    "                self.moves_since_hint = 0\n",
    "            return random_index\n",
    "        act_values = self.model.predict(state)\n",
    "        nonrandom_index = np.argmax(act_values[0])  # returns action\n",
    "        if nonrandom_index == 0:\n",
    "            self.moves_since_hint += 1\n",
    "        else:\n",
    "            self.moves_since_hint = 0\n",
    "        return nonrandom_index\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, int(batch_size))\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            # if not done: #USED TO BE COMMENTED IN\n",
    "            #print (\"teacher agent state (should be an array with shape (4, )): \", next_state)\n",
    "            # target = (reward + self.gamma *\n",
    "            #           np.amax(self.model.predict(next_state)[0]))\n",
    "            whole_list = self.model.predict(next_state)\n",
    "            amax_result = np.amax(whole_list[0])\n",
    "            target = reward + self.gamma * amax_result\n",
    "            # tabbed over part above\n",
    "\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_agent = TeacherAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 75        \n",
      "=================================================================\n",
      "Total params: 795\n",
      "Trainable params: 795\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(teacher_agent.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(teacher_agent.model, to_file='teacher_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"264pt\" viewBox=\"0.00 0.00 113.00 264.00\" width=\"113pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 260)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 109,-260 109,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 47861913024 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>47861913024</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 105,-182.5 105,-146.5 0,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"52.5\" y=\"-160.8\">dense_7: Dense</text>\n",
       "</g>\n",
       "<!-- 47861184160 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>47861184160</title>\n",
       "<polygon fill=\"none\" points=\"0,-73.5 0,-109.5 105,-109.5 105,-73.5 0,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"52.5\" y=\"-87.8\">dense_8: Dense</text>\n",
       "</g>\n",
       "<!-- 47861913024&#45;&gt;47861184160 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>47861913024-&gt;47861184160</title>\n",
       "<path d=\"M52.5,-146.4551C52.5,-138.3828 52.5,-128.6764 52.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"56.0001,-119.5903 52.5,-109.5904 49.0001,-119.5904 56.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47861913808 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>47861913808</title>\n",
       "<polygon fill=\"none\" points=\"0,-.5 0,-36.5 105,-36.5 105,-.5 0,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"52.5\" y=\"-14.8\">dense_9: Dense</text>\n",
       "</g>\n",
       "<!-- 47861184160&#45;&gt;47861913808 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>47861184160-&gt;47861913808</title>\n",
       "<path d=\"M52.5,-73.4551C52.5,-65.3828 52.5,-55.6764 52.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"56.0001,-46.5903 52.5,-36.5904 49.0001,-46.5904 56.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47861913136 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>47861913136</title>\n",
       "<polygon fill=\"none\" points=\"5.5,-219.5 5.5,-255.5 99.5,-255.5 99.5,-219.5 5.5,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"52.5\" y=\"-233.8\">47861913136</text>\n",
       "</g>\n",
       "<!-- 47861913136&#45;&gt;47861913024 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>47861913136-&gt;47861913024</title>\n",
       "<path d=\"M52.5,-219.4551C52.5,-211.3828 52.5,-201.6764 52.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"56.0001,-192.5903 52.5,-182.5904 49.0001,-192.5904 56.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(teacher_agent.model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megumisano/anaconda/lib/python3.6/subprocess.py:766: ResourceWarning: subprocess 88060 is still running\n",
      "  ResourceWarning, source=self)\n",
      "/Users/megumisano/anaconda/lib/python3.6/subprocess.py:766: ResourceWarning: subprocess 88065 is still running\n",
      "  ResourceWarning, source=self)\n",
      "/Users/megumisano/anaconda/lib/python3.6/subprocess.py:766: ResourceWarning: subprocess 88069 is still running\n",
      "  ResourceWarning, source=self)\n"
     ]
    }
   ],
   "source": [
    "ann_viz(teacher_agent.model, title=\"My second neural network\", view=True, filename = 'teacher.gv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
